{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalgo-intern/team-a/blob/master/src/learning/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXxIEd63LH9S",
        "colab_type": "text"
      },
      "source": [
        "# **機械学習コード**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o3ggDXWrdHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMOs3RoQLTWJ",
        "colab_type": "text"
      },
      "source": [
        "前処理済みの学習データであるtrainフォルダとvalidationフォルダを圧縮してからGoogleDriveにあげて共有可能なリンクを取得してid以下を下のセルの該当箇所にそれぞれ入力する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8KO-fwWs28Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1WxOK8oyxZ_jJkaJ4zLa_nbfnmDijh0M9'}) #共有可能なリンクのid以下を入力\n",
        "\n",
        "downloaded.GetContentFile('train.zip') #圧縮してドライブにあげたtrainフォルダ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfhHGpmwtRX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1oiDVeU8A14ukiD247w8G_xueVhwiy2uK'})\n",
        "\n",
        "downloaded.GetContentFile('validation.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykJbu-SQtdmX",
        "colab_type": "code",
        "outputId": "77178fa6-347d-455a-c105-7d6be6fbe300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#学習データを解凍\n",
        "!unzip train.zip\n",
        "!unzip validation.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.zip\n",
            "   creating: train/chimpanzee/\n",
            "  inflating: train/chimpanzee/10037667855.jpg  \n",
            "  inflating: train/chimpanzee/10059377785.jpg  \n",
            "  inflating: train/chimpanzee/10803455094.jpg  \n",
            "  inflating: train/chimpanzee/11581412744.jpg  \n",
            "  inflating: train/chimpanzee/11950809213.jpg  \n",
            "  inflating: train/chimpanzee/12184235744.jpg  \n",
            "  inflating: train/chimpanzee/14974695853.jpg  \n",
            "  inflating: train/chimpanzee/14993392243.jpg  \n",
            "  inflating: train/chimpanzee/15039218068.jpg  \n",
            "  inflating: train/chimpanzee/15165394638.jpg  \n",
            "  inflating: train/chimpanzee/15276624803.jpg  \n",
            "  inflating: train/chimpanzee/15610867861.jpg  \n",
            "  inflating: train/chimpanzee/15618200812.jpg  \n",
            "  inflating: train/chimpanzee/15657269754.jpg  \n",
            "  inflating: train/chimpanzee/15896275615.jpg  \n",
            "  inflating: train/chimpanzee/16115811169.jpg  \n",
            "  inflating: train/chimpanzee/16277952091.jpg  \n",
            "  inflating: train/chimpanzee/16501300762.jpg  \n",
            "  inflating: train/chimpanzee/16624083417.jpg  \n",
            "  inflating: train/chimpanzee/166992783.jpg  \n",
            "  inflating: train/chimpanzee/167328694.jpg  \n",
            "  inflating: train/chimpanzee/167328770.jpg  \n",
            "  inflating: train/chimpanzee/22698302113.jpg  \n",
            "  inflating: train/chimpanzee/23037668675.jpg  \n",
            "  inflating: train/chimpanzee/23048873991.jpg  \n",
            "  inflating: train/chimpanzee/23521829324.jpg  \n",
            "  inflating: train/chimpanzee/25739933352.jpg  \n",
            "  inflating: train/chimpanzee/2654309938.jpg  \n",
            "  inflating: train/chimpanzee/27027802446.jpg  \n",
            "  inflating: train/chimpanzee/27782497597.jpg  \n",
            "  inflating: train/chimpanzee/28922201883.jpg  \n",
            "  inflating: train/chimpanzee/2931872877.jpg  \n",
            "  inflating: train/chimpanzee/30921414737.jpg  \n",
            "  inflating: train/chimpanzee/3105152541.jpg  \n",
            "  inflating: train/chimpanzee/31668083635.jpg  \n",
            "  inflating: train/chimpanzee/32061320867.jpg  \n",
            "  inflating: train/chimpanzee/32345189407.jpg  \n",
            "  inflating: train/chimpanzee/32382328807.jpg  \n",
            "  inflating: train/chimpanzee/3253635631.jpg  \n",
            "  inflating: train/chimpanzee/32717648106.jpg  \n",
            "  inflating: train/chimpanzee/32758614457.jpg  \n",
            "  inflating: train/chimpanzee/33502127540.jpg  \n",
            "  inflating: train/chimpanzee/3380419269.jpg  \n",
            "  inflating: train/chimpanzee/34043902782.jpg  \n",
            "  inflating: train/chimpanzee/34148696046.jpg  \n",
            "  inflating: train/chimpanzee/34765616100.jpg  \n",
            "  inflating: train/chimpanzee/3507560023.jpg  \n",
            "  inflating: train/chimpanzee/35353594152.jpg  \n",
            "  inflating: train/chimpanzee/35829807564.jpg  \n",
            "  inflating: train/chimpanzee/37048674136.jpg  \n",
            "  inflating: train/chimpanzee/3743172664.jpg  \n",
            "  inflating: train/chimpanzee/41613475782.jpg  \n",
            "  inflating: train/chimpanzee/4180375982.jpg  \n",
            "  inflating: train/chimpanzee/45648509644.jpg  \n",
            "  inflating: train/chimpanzee/4639443982.jpg  \n",
            "  inflating: train/chimpanzee/46573276092.jpg  \n",
            "  inflating: train/chimpanzee/47428060602.jpg  \n",
            "  inflating: train/chimpanzee/47523167171.jpg  \n",
            "  inflating: train/chimpanzee/47527792732.jpg  \n",
            "  inflating: train/chimpanzee/4807160797.jpg  \n",
            "  inflating: train/chimpanzee/5514314502.jpg  \n",
            "  inflating: train/chimpanzee/5519511070.jpg  \n",
            "  inflating: train/chimpanzee/5528498993.jpg  \n",
            "  inflating: train/chimpanzee/5612164542.jpg  \n",
            "  inflating: train/chimpanzee/5625060461.jpg  \n",
            "  inflating: train/chimpanzee/5936969040.jpg  \n",
            "  inflating: train/chimpanzee/6148356989.jpg  \n",
            "  inflating: train/chimpanzee/6148913840.jpg  \n",
            "  inflating: train/chimpanzee/6263436793.jpg  \n",
            "  inflating: train/chimpanzee/7101027279.jpg  \n",
            "  inflating: train/chimpanzee/7256564776.jpg  \n",
            "  inflating: train/chimpanzee/7760320216.jpg  \n",
            "  inflating: train/chimpanzee/7763711272.jpg  \n",
            "  inflating: train/chimpanzee/7841322394.jpg  \n",
            "  inflating: train/chimpanzee/7972546400.jpg  \n",
            "  inflating: train/chimpanzee/8032341125.jpg  \n",
            "  inflating: train/chimpanzee/8032343081.jpg  \n",
            "  inflating: train/chimpanzee/8059232711.jpg  \n",
            "  inflating: train/chimpanzee/8085053289.jpg  \n",
            "  inflating: train/chimpanzee/8113179917.jpg  \n",
            "  inflating: train/chimpanzee/8198082007.jpg  \n",
            "  inflating: train/chimpanzee/8201497608.jpg  \n",
            "  inflating: train/chimpanzee/8234610687.jpg  \n",
            "  inflating: train/chimpanzee/8234612481.jpg  \n",
            "  inflating: train/chimpanzee/8238235389.jpg  \n",
            "  inflating: train/chimpanzee/8267735672.jpg  \n",
            "  inflating: train/chimpanzee/8416828546.jpg  \n",
            "  inflating: train/chimpanzee/8417816542.jpg  \n",
            "  inflating: train/chimpanzee/8469021530.jpg  \n",
            "  inflating: train/chimpanzee/8469022594.jpg  \n",
            "  inflating: train/chimpanzee/8928335627.jpg  \n",
            "  inflating: train/chimpanzee/9342924159.jpg  \n",
            "  inflating: train/chimpanzee/9365953398.jpg  \n",
            "  inflating: train/chimpanzee/9685648951.jpg  \n",
            "  inflating: train/chimpanzee/9733518212.jpg  \n",
            "  inflating: train/chimpanzee/9847571584.jpg  \n",
            "   creating: train/gorilla/\n",
            "  inflating: train/gorilla/10057946.jpg  \n",
            "  inflating: train/gorilla/10070038356.jpg  \n",
            "  inflating: train/gorilla/10361564863.jpg  \n",
            "  inflating: train/gorilla/1055053898.jpg  \n",
            "  inflating: train/gorilla/10604947664.jpg  \n",
            "  inflating: train/gorilla/11416446263.jpg  \n",
            "  inflating: train/gorilla/11530487486.jpg  \n",
            "  inflating: train/gorilla/1383495361.jpg  \n",
            "  inflating: train/gorilla/13883344243.jpg  \n",
            "  inflating: train/gorilla/1393544284.jpg  \n",
            "  inflating: train/gorilla/141641384.jpg  \n",
            "  inflating: train/gorilla/14255962274.jpg  \n",
            "  inflating: train/gorilla/14259694395.jpg  \n",
            "  inflating: train/gorilla/14829448176.jpg  \n",
            "  inflating: train/gorilla/14944416951.jpg  \n",
            "  inflating: train/gorilla/15375819139.jpg  \n",
            "  inflating: train/gorilla/15562627758.jpg  \n",
            "  inflating: train/gorilla/15619272140.jpg  \n",
            "  inflating: train/gorilla/15841018256.jpg  \n",
            "  inflating: train/gorilla/16018693155.jpg  \n",
            "  inflating: train/gorilla/17073877127.jpg  \n",
            "  inflating: train/gorilla/173320397.jpg  \n",
            "  inflating: train/gorilla/174888866.jpg  \n",
            "  inflating: train/gorilla/17721052099.jpg  \n",
            "  inflating: train/gorilla/2078180122.jpg  \n",
            "  inflating: train/gorilla/2166595014.jpg  \n",
            "  inflating: train/gorilla/2243270762.jpg  \n",
            "  inflating: train/gorilla/22459966312.jpg  \n",
            "  inflating: train/gorilla/22484363941.jpg  \n",
            "  inflating: train/gorilla/2506576884.jpg  \n",
            "  inflating: train/gorilla/2623796462.jpg  \n",
            "  inflating: train/gorilla/2740685641.jpg  \n",
            "  inflating: train/gorilla/286459056.jpg  \n",
            "  inflating: train/gorilla/2914008619.jpg  \n",
            "  inflating: train/gorilla/3187156650.jpg  \n",
            "  inflating: train/gorilla/33265258652.jpg  \n",
            "  inflating: train/gorilla/35217956065.jpg  \n",
            "  inflating: train/gorilla/3545887001.jpg  \n",
            "  inflating: train/gorilla/35474500030.jpg  \n",
            "  inflating: train/gorilla/3551807265.jpg  \n",
            "  inflating: train/gorilla/35951865445.jpg  \n",
            "  inflating: train/gorilla/36566932610.jpg  \n",
            "  inflating: train/gorilla/3735057699.jpg  \n",
            "  inflating: train/gorilla/3785306855.jpg  \n",
            "  inflating: train/gorilla/3821765774.jpg  \n",
            "  inflating: train/gorilla/3827465833.jpg  \n",
            "  inflating: train/gorilla/3828268896.jpg  \n",
            "  inflating: train/gorilla/3875111845.jpg  \n",
            "  inflating: train/gorilla/38901448924.jpg  \n",
            "  inflating: train/gorilla/402529346.jpg  \n",
            "  inflating: train/gorilla/411233537.jpg  \n",
            "  inflating: train/gorilla/4287301929.jpg  \n",
            "  inflating: train/gorilla/44002050980.jpg  \n",
            "  inflating: train/gorilla/441665738.jpg  \n",
            "  inflating: train/gorilla/4835730140.jpg  \n",
            "  inflating: train/gorilla/4928777966.jpg  \n",
            "  inflating: train/gorilla/4939266727.jpg  \n",
            "  inflating: train/gorilla/498556593.jpg  \n",
            "  inflating: train/gorilla/5132533789.jpg  \n",
            "  inflating: train/gorilla/5226854274.jpg  \n",
            "  inflating: train/gorilla/54997969.jpg  \n",
            "  inflating: train/gorilla/5552163420.jpg  \n",
            "  inflating: train/gorilla/5602558885.jpg  \n",
            "  inflating: train/gorilla/5637804447.jpg  \n",
            "  inflating: train/gorilla/5886958428.jpg  \n",
            "  inflating: train/gorilla/5939913542.jpg  \n",
            "  inflating: train/gorilla/6018511838.jpg  \n",
            "  inflating: train/gorilla/6078118437.jpg  \n",
            "  inflating: train/gorilla/6198637891.jpg  \n",
            "  inflating: train/gorilla/6431097329.jpg  \n",
            "  inflating: train/gorilla/6434731461.jpg  \n",
            "  inflating: train/gorilla/6434732597.jpg  \n",
            "  inflating: train/gorilla/6454564819.jpg  \n",
            "  inflating: train/gorilla/65995173.jpg  \n",
            "  inflating: train/gorilla/6845464192.jpg  \n",
            "  inflating: train/gorilla/7215675976.jpg  \n",
            "  inflating: train/gorilla/7569138132.jpg  \n",
            "  inflating: train/gorilla/7790472230.jpg  \n",
            "  inflating: train/gorilla/7810300764.jpg  \n",
            "  inflating: train/gorilla/7858533006.jpg  \n",
            "  inflating: train/gorilla/8000097050.jpg  \n",
            "  inflating: train/gorilla/8074934854.jpg  \n",
            "  inflating: train/gorilla/812103234.jpg  \n",
            "  inflating: train/gorilla/8187598378.jpg  \n",
            "  inflating: train/gorilla/8198958121.jpg  \n",
            "  inflating: train/gorilla/8234487063.jpg  \n",
            "  inflating: train/gorilla/8556091250.jpg  \n",
            "  inflating: train/gorilla/8628658275.jpg  \n",
            "  inflating: train/gorilla/8656381727.jpg  \n",
            "  inflating: train/gorilla/8730404593.jpg  \n",
            "  inflating: train/gorilla/8731525850.jpg  \n",
            "  inflating: train/gorilla/8989076090.jpg  \n",
            "  inflating: train/gorilla/9103117354.jpg  \n",
            "  inflating: train/gorilla/9232320238.jpg  \n",
            "  inflating: train/gorilla/9261815510.jpg  \n",
            "  inflating: train/gorilla/9773241406.jpg  \n",
            "   creating: train/monkey/\n",
            "  inflating: train/monkey/10666178983.jpg  \n",
            "  inflating: train/monkey/11428986973.jpg  \n",
            "  inflating: train/monkey/11512536214.jpg  \n",
            "  inflating: train/monkey/11859490534.jpg  \n",
            "  inflating: train/monkey/11859584445.jpg  \n",
            "  inflating: train/monkey/12701577405.jpg  \n",
            "  inflating: train/monkey/12712968864.jpg  \n",
            "  inflating: train/monkey/13720802034.jpg  \n",
            "  inflating: train/monkey/15010678181.jpg  \n",
            "  inflating: train/monkey/1525951623.jpg  \n",
            "  inflating: train/monkey/1525961549.jpg  \n",
            "  inflating: train/monkey/1526016605.jpg  \n",
            "  inflating: train/monkey/15280942937.jpg  \n",
            "  inflating: train/monkey/15305672090.jpg  \n",
            "  inflating: train/monkey/15525739132.jpg  \n",
            "  inflating: train/monkey/16195146430.jpg  \n",
            "  inflating: train/monkey/16196632567.jpg  \n",
            "  inflating: train/monkey/16381601552.jpg  \n",
            "  inflating: train/monkey/16381652512.jpg  \n",
            "  inflating: train/monkey/16382542775.jpg  \n",
            "  inflating: train/monkey/16386739251.jpg  \n",
            "  inflating: train/monkey/16482348836.jpg  \n",
            "  inflating: train/monkey/16493734726.jpg  \n",
            "  inflating: train/monkey/16601946122.jpg  \n",
            "  inflating: train/monkey/16894894878.jpg  \n",
            "  inflating: train/monkey/20553817220.jpg  \n",
            "  inflating: train/monkey/21985312253.jpg  \n",
            "  inflating: train/monkey/2515105676.jpg  \n",
            "  inflating: train/monkey/25854947667.jpg  \n",
            "  inflating: train/monkey/25875272067.jpg  \n",
            "  inflating: train/monkey/26142438332.jpg  \n",
            "  inflating: train/monkey/26245171291.jpg  \n",
            "  inflating: train/monkey/26654140151.jpg  \n",
            "  inflating: train/monkey/26730528160.jpg  \n",
            "  inflating: train/monkey/26875257508.jpg  \n",
            "  inflating: train/monkey/30593124587.jpg  \n",
            "  inflating: train/monkey/31310339227.jpg  \n",
            "  inflating: train/monkey/32124789945.jpg  \n",
            "  inflating: train/monkey/32635614387.jpg  \n",
            "  inflating: train/monkey/32793576754.jpg  \n",
            "  inflating: train/monkey/33385845048.jpg  \n",
            "  inflating: train/monkey/33594225078.jpg  \n",
            "  inflating: train/monkey/34583518196.jpg  \n",
            "  inflating: train/monkey/34995896873.jpg  \n",
            "  inflating: train/monkey/35015944770.jpg  \n",
            "  inflating: train/monkey/3607050549.jpg  \n",
            "  inflating: train/monkey/37316164841.jpg  \n",
            "  inflating: train/monkey/37617231652.jpg  \n",
            "  inflating: train/monkey/37626868406.jpg  \n",
            "  inflating: train/monkey/37646228952.jpg  \n",
            "  inflating: train/monkey/37774148741.jpg  \n",
            "  inflating: train/monkey/38045595966.jpg  \n",
            "  inflating: train/monkey/38098247721.jpg  \n",
            "  inflating: train/monkey/38141515156.jpg  \n",
            "  inflating: train/monkey/38723977551.jpg  \n",
            "  inflating: train/monkey/41396695604.jpg  \n",
            "  inflating: train/monkey/41396696114.jpg  \n",
            "  inflating: train/monkey/44115312230.jpg  \n",
            "  inflating: train/monkey/4414109489.jpg  \n",
            "  inflating: train/monkey/45533993401.jpg  \n",
            "  inflating: train/monkey/4588552982.jpg  \n",
            "  inflating: train/monkey/46625849995.jpg  \n",
            "  inflating: train/monkey/46662537495.jpg  \n",
            "  inflating: train/monkey/47242626311.jpg  \n",
            "  inflating: train/monkey/47672244592.jpg  \n",
            "  inflating: train/monkey/5145178942.jpg  \n",
            "  inflating: train/monkey/5339114099.jpg  \n",
            "  inflating: train/monkey/5446512365.jpg  \n",
            "  inflating: train/monkey/5746316179.jpg  \n",
            "  inflating: train/monkey/5896303640.jpg  \n",
            "  inflating: train/monkey/5896347334.jpg  \n",
            "  inflating: train/monkey/5917187605.jpg  \n",
            "  inflating: train/monkey/5959360319.jpg  \n",
            "  inflating: train/monkey/6128974945.jpg  \n",
            "  inflating: train/monkey/6797033503.jpg  \n",
            "  inflating: train/monkey/6840052447.jpg  \n",
            "  inflating: train/monkey/6840065115.jpg  \n",
            "  inflating: train/monkey/7837797008.jpg  \n",
            "  inflating: train/monkey/8289735445.jpg  \n",
            "  inflating: train/monkey/8417386916.jpg  \n",
            "  inflating: train/monkey/8417531279.jpg  \n",
            "  inflating: train/monkey/8417541225.jpg  \n",
            "  inflating: train/monkey/8520760769.jpg  \n",
            "  inflating: train/monkey/8521690792.jpg  \n",
            "  inflating: train/monkey/8521890078.jpg  \n",
            "  inflating: train/monkey/8522153714.jpg  \n",
            "  inflating: train/monkey/8522172168.jpg  \n",
            "  inflating: train/monkey/c2059851232.jpg  \n",
            "  inflating: train/monkey/c2555916771.jpg  \n",
            "  inflating: train/monkey/c3066431853.jpg  \n",
            "  inflating: train/monkey/c3226155812.jpg  \n",
            "  inflating: train/monkey/c3607050735.jpg  \n",
            "  inflating: train/monkey/c3607055035.jpg  \n",
            "  inflating: train/monkey/c3688241054.jpg  \n",
            "  inflating: train/monkey/c3838554605.jpg  \n",
            "  inflating: train/monkey/c4048306554.jpg  \n",
            "Archive:  validation.zip\n",
            "replace validation/chimpanzee/11950809233.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: validation/chimpanzee/11950809233.jpg  \n",
            "  inflating: validation/chimpanzee/11950809253.jpg  \n",
            "  inflating: validation/chimpanzee/11966528644.jpg  \n",
            "  inflating: validation/chimpanzee/14916048166.jpg  \n",
            "  inflating: validation/chimpanzee/15924817017.jpg  \n",
            "  inflating: validation/chimpanzee/16197859124.jpg  \n",
            "  inflating: validation/chimpanzee/25955172143.jpg  \n",
            "  inflating: validation/chimpanzee/26457074493.jpg  \n",
            "  inflating: validation/chimpanzee/3017601544.jpg  \n",
            "  inflating: validation/chimpanzee/32504606377.jpg  \n",
            "  inflating: validation/chimpanzee/3380377939.jpg  \n",
            "  inflating: validation/chimpanzee/36074179502.jpg  \n",
            "  inflating: validation/chimpanzee/45711151045.jpg  \n",
            "  inflating: validation/chimpanzee/47548610291.jpg  \n",
            "  inflating: validation/chimpanzee/5216632993.jpg  \n",
            "  inflating: validation/chimpanzee/5930298589.jpg  \n",
            "  inflating: validation/chimpanzee/6263454725.jpg  \n",
            "  inflating: validation/chimpanzee/6822938730.jpg  \n",
            "  inflating: validation/chimpanzee/7256595984.jpg  \n",
            "  inflating: validation/chimpanzee/7692428548.jpg  \n",
            "  inflating: validation/chimpanzee/8287741023.jpg  \n",
            "  inflating: validation/chimpanzee/8483604744.jpg  \n",
            "  inflating: validation/chimpanzee/8551454383.jpg  \n",
            "  inflating: validation/chimpanzee/9678800009.jpg  \n",
            "  inflating: validation/gorilla/12261123623.jpg  \n",
            "  inflating: validation/gorilla/15461447313.jpg  \n",
            "  inflating: validation/gorilla/16766126650.jpg  \n",
            "  inflating: validation/gorilla/17908414745.jpg  \n",
            "  inflating: validation/gorilla/23683068319.jpg  \n",
            "  inflating: validation/gorilla/2401698195.jpg  \n",
            "  inflating: validation/gorilla/3159666520.jpg  \n",
            "  inflating: validation/gorilla/3449005318.jpg  \n",
            "  inflating: validation/gorilla/34826784052.jpg  \n",
            "  inflating: validation/gorilla/3676397341.jpg  \n",
            "  inflating: validation/gorilla/5300107311.jpg  \n",
            "  inflating: validation/gorilla/5561802113.jpg  \n",
            "  inflating: validation/gorilla/6040544805.jpg  \n",
            "  inflating: validation/gorilla/6050872610.jpg  \n",
            "  inflating: validation/gorilla/6065859638.jpg  \n",
            "  inflating: validation/gorilla/61013344.jpg  \n",
            "  inflating: validation/gorilla/6214153825.jpg  \n",
            "  inflating: validation/gorilla/6292204763.jpg  \n",
            "  inflating: validation/gorilla/7229319628.jpg  \n",
            "  inflating: validation/gorilla/7467631380.jpg  \n",
            "  inflating: validation/gorilla/8730397705.jpg  \n",
            "  inflating: validation/gorilla/8730399665.jpg  \n",
            "  inflating: validation/gorilla/9116906710.jpg  \n",
            "  inflating: validation/gorilla/9278621744.jpg  \n",
            "  inflating: validation/monkey/11859448524.jpg  \n",
            "  inflating: validation/monkey/15599735722.jpg  \n",
            "  inflating: validation/monkey/15949680656.jpg  \n",
            "  inflating: validation/monkey/16422882031.jpg  \n",
            "  inflating: validation/monkey/16447467672.jpg  \n",
            "  inflating: validation/monkey/23617354500.jpg  \n",
            "  inflating: validation/monkey/24284166389.jpg  \n",
            "  inflating: validation/monkey/24337817686.jpg  \n",
            "  inflating: validation/monkey/25760501267.jpg  \n",
            "  inflating: validation/monkey/32029228865.jpg  \n",
            "  inflating: validation/monkey/3225288757.jpg  \n",
            "  inflating: validation/monkey/33456044743.jpg  \n",
            "  inflating: validation/monkey/36965634384.jpg  \n",
            "  inflating: validation/monkey/37350814524.jpg  \n",
            "  inflating: validation/monkey/4247242182.jpg  \n",
            "  inflating: validation/monkey/4247243970.jpg  \n",
            "  inflating: validation/monkey/43204823565.jpg  \n",
            "  inflating: validation/monkey/5480840802.jpg  \n",
            "  inflating: validation/monkey/5488946019.jpg  \n",
            "  inflating: validation/monkey/5751831980.jpg  \n",
            "  inflating: validation/monkey/5959922042.jpg  \n",
            "  inflating: validation/monkey/6840048033.jpg  \n",
            "  inflating: validation/monkey/6840049711.jpg  \n",
            "  inflating: validation/monkey/c1525961549.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1hs4w3aL3tZ",
        "colab_type": "text"
      },
      "source": [
        "### 転移学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5i4j_YZtlvG",
        "colab_type": "code",
        "outputId": "87602b76-f348-4e6a-9f0e-2fedba1a3f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#モデルの設計（ニューラルネットワークモデル）\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense,Input,GlobalMaxPooling2D,Dropout\n",
        "from keras.applications.vgg16 import VGG16 #keras.applications.vgg16モジュールに入っている学習済みモデルVGG16をインポート\n",
        "from keras.preprocessing.image import ImageDataGenerator #訓練データと検証データを生成する道具をインポート\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "N_CATEGORIES = 3 #分類するクラスの数を入力\n",
        "IMAGE_SIZE = 224 #使う画像の大きさ\n",
        "BATCH_SIZE = 8 #1バッチ（訓練データの1かたまり）に含めるデータ数であるバッチサイズを入力\n",
        "\n",
        "NUM_TRAINING = 288 #訓練データの総数を入力\n",
        "NUM_VALIDATION = 72 #検証データの総数を入力\n",
        "\n",
        "#入力するデータのサイズを指定（切り取りではなく引き延ばし）\n",
        "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) #引数は、(縦, 横,RGB)\n",
        "\n",
        "#重みと、VGG16のフル結合層を含むかどうかと、入力データを指定\n",
        "base_model = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor)\n",
        "#imagnetとすることで、ImageNetImageNetを使って学習した重みになる。\n",
        "#VGG16の1000分類を使わないのでFalseとする。\n",
        "#入力データをinput_tensorとする。\n",
        "\n",
        "#学習済みモデルに独自の層を追加\n",
        "x = base_model.output\n",
        "x = GlobalMaxPooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dropout(.25)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "\n",
        "predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers[:15]:\n",
        "   layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=SGD(lr=1e-4, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.summary() #モデル構造（VGG16の層と独自に作った層）を見る\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   shear_range=0,\n",
        "   zoom_range=0.1,\n",
        "   horizontal_flip=True,\n",
        "   rotation_range=0)\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "   'train',\n",
        "   target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "   batch_size=BATCH_SIZE,\n",
        "   class_mode='categorical',\n",
        "   shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "   'validation',\n",
        "   target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "   batch_size=BATCH_SIZE,\n",
        "   class_mode='categorical',\n",
        "   shuffle=True\n",
        ")\n",
        "\n",
        "hist = model.fit_generator(train_generator,\n",
        "   steps_per_epoch=NUM_TRAINING//BATCH_SIZE,\n",
        "   epochs=50, #訓練データを何回学習させるかというエポック数を入力\n",
        "   verbose=1, #0だとログを出力せず、1だと標準出力、2はエポックごとに1行のログを出力\n",
        "   validation_data=validation_generator,\n",
        "   validation_steps=NUM_VALIDATION//BATCH_SIZE,\n",
        "   )\n",
        "#monkey.hdf5という形でモデルを保存\n",
        "\n",
        "model.save('monkey.hdf5')\n",
        "\n",
        "\n",
        "#↓学習の進捗状況・精度のログ"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0830 03:30:10.501474 140300576204672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0830 03:30:10.516591 140300576204672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0830 03:30:10.519755 140300576204672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0830 03:30:10.549531 140300576204672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0830 03:30:10.940183 140300576204672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0830 03:30:10.941810 140300576204672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0830 03:30:11.714937 140300576204672 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0830 03:30:11.849548 140300576204672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2048)              2099200   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 19,440,451\n",
            "Trainable params: 11,805,187\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "Found 288 images belonging to 3 classes.\n",
            "Found 72 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0830 03:30:12.203651 140300576204672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 9s 257ms/step - loss: 1.1077 - acc: 0.3403 - val_loss: 1.0379 - val_acc: 0.4861\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.9953 - acc: 0.5417 - val_loss: 0.9573 - val_acc: 0.5417\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.8734 - acc: 0.6424 - val_loss: 0.8622 - val_acc: 0.6528\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.7703 - acc: 0.7535 - val_loss: 0.7743 - val_acc: 0.7083\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.6598 - acc: 0.7951 - val_loss: 0.7071 - val_acc: 0.7500\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.5872 - acc: 0.8090 - val_loss: 0.6142 - val_acc: 0.7083\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.4698 - acc: 0.8854 - val_loss: 0.5429 - val_acc: 0.8333\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.3993 - acc: 0.9028 - val_loss: 0.4629 - val_acc: 0.8056\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.3237 - acc: 0.9132 - val_loss: 0.4148 - val_acc: 0.8194\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.2736 - acc: 0.9306 - val_loss: 0.3491 - val_acc: 0.9167\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.2153 - acc: 0.9514 - val_loss: 0.3378 - val_acc: 0.8333\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.1921 - acc: 0.9653 - val_loss: 0.2661 - val_acc: 0.9028\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.1525 - acc: 0.9653 - val_loss: 0.2394 - val_acc: 0.9167\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.1358 - acc: 0.9757 - val_loss: 0.2344 - val_acc: 0.9028\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.1234 - acc: 0.9757 - val_loss: 0.2014 - val_acc: 0.9028\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.1152 - acc: 0.9688 - val_loss: 0.2030 - val_acc: 0.9167\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0874 - acc: 0.9896 - val_loss: 0.1836 - val_acc: 0.9167\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0826 - acc: 0.9896 - val_loss: 0.1523 - val_acc: 0.9306\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0618 - acc: 0.9931 - val_loss: 0.1584 - val_acc: 0.9306\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0662 - acc: 0.9896 - val_loss: 0.1640 - val_acc: 0.9306\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0456 - acc: 0.9965 - val_loss: 0.1672 - val_acc: 0.9167\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0558 - acc: 0.9896 - val_loss: 0.1606 - val_acc: 0.9167\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.1652 - val_acc: 0.9167\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0390 - acc: 0.9965 - val_loss: 0.1303 - val_acc: 0.9306\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.1494 - val_acc: 0.9444\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 0.9167\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0258 - acc: 0.9965 - val_loss: 0.1412 - val_acc: 0.9306\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.1443 - val_acc: 0.9306\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.1497 - val_acc: 0.9167\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.1583 - val_acc: 0.9306\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.1534 - val_acc: 0.9167\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.9306\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.1645 - val_acc: 0.9306\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.1393 - val_acc: 0.9306\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.1317 - val_acc: 0.9306\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1591 - val_acc: 0.9444\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.1296 - val_acc: 0.9167\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.1310 - val_acc: 0.9306\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.1451 - val_acc: 0.9306\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9306\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.1346 - val_acc: 0.9167\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.1421 - val_acc: 0.9306\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 0.9306\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.1688 - val_acc: 0.9583\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9306\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0115 - acc: 0.9965 - val_loss: 0.1257 - val_acc: 0.9167\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1488 - val_acc: 0.9306\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.1543 - val_acc: 0.9444\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.1477 - val_acc: 0.9306\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.1459 - val_acc: 0.9306\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1468 - val_acc: 0.9306\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9444\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9306\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.1457 - val_acc: 0.9306\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1306 - val_acc: 0.9306\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.1462 - val_acc: 0.9583\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9444\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 6s 168ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.1563 - val_acc: 0.9583\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 6s 169ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1149 - val_acc: 0.9306\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 6s 170ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1261 - val_acc: 0.9306\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1347 - val_acc: 0.9306\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.1273 - val_acc: 0.9306\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1383 - val_acc: 0.9306\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1372 - val_acc: 0.9306\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1197 - val_acc: 0.9306\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9306\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1242 - val_acc: 0.9306\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 0.9306\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1463 - val_acc: 0.9444\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1298 - val_acc: 0.9306\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9306\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1356 - val_acc: 0.9444\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1520 - val_acc: 0.9444\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1482 - val_acc: 0.9444\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1292 - val_acc: 0.9306\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1279 - val_acc: 0.9306\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1407 - val_acc: 0.9583\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9444\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9306\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1288 - val_acc: 0.9306\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1454 - val_acc: 0.9583\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1498 - val_acc: 0.9583\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9583\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9444\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9444\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1288 - val_acc: 0.9306\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9583\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1526 - val_acc: 0.9583\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1642 - val_acc: 0.9583\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 0.9444\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9306\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9306\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1371 - val_acc: 0.9444\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1544 - val_acc: 0.9444\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 6s 172ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1434 - val_acc: 0.9583\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 6s 171ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1512 - val_acc: 0.9583\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1713 - val_acc: 0.9583\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1487 - val_acc: 0.9583\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 6s 174ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1606 - val_acc: 0.9583\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 6s 173ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-NVj286xUVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_file_2 = drive.CreateFile()\n",
        "upload_file_2.SetContentFile(\"monkey.hdf5\")\n",
        "upload_file_2.Upload()\n",
        "#マイドライブに monkey.hdf5  があがる。"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}